{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import xml.etree.ElementTree as ET\n",
        "import time\n",
        "\n",
        "def parse_date(date_string):\n",
        "    \"\"\"Parse and format date for Excel compatibility\"\"\"\n",
        "    if not date_string or date_string == \"No date\":\n",
        "        return \"Unknown\"\n",
        "\n",
        "    # Common RSS date formats\n",
        "    date_formats = [\n",
        "        '%a, %d %b %Y %H:%M:%S %z',  # RFC 822 with timezone\n",
        "        '%a, %d %b %Y %H:%M:%S %Z',  # RFC 822 with timezone name\n",
        "        '%a, %d %b %Y %H:%M:%S',     # RFC 822 without timezone\n",
        "        '%Y-%m-%dT%H:%M:%S%z',       # ISO 8601 format\n",
        "        '%Y-%m-%d %H:%M:%S'          # Simple format\n",
        "    ]\n",
        "\n",
        "    for fmt in date_formats:\n",
        "        try:\n",
        "            parsed_date = datetime.strptime(date_string, fmt)\n",
        "            # Format for Excel compatibility (YYYY-MM-DD HH:MM:SS)\n",
        "            return parsed_date.strftime('%Y-%m-%d %H:%M:%S')\n",
        "        except ValueError:\n",
        "            continue\n",
        "\n",
        "    # If all parsing fails, return the original string\n",
        "    return date_string\n",
        "\n",
        "def fetch_techcrunch_headlines():\n",
        "    \"\"\"Fetch recent headlines from TechCrunch RSS feed\"\"\"\n",
        "    try:\n",
        "        url = \"https://techcrunch.com/feed/\"\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
        "        }\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        root = ET.fromstring(response.content)\n",
        "        headlines = []\n",
        "\n",
        "        # Parse RSS items\n",
        "        for item in root.findall('.//item')[:4]:\n",
        "            title = item.find('title').text if item.find('title') is not None else \"No title\"\n",
        "            link = item.find('link').text if item.find('link') is not None else \"No link\"\n",
        "            pub_date = item.find('pubDate').text if item.find('pubDate') is not None else \"No date\"\n",
        "\n",
        "            # Parse and format date\n",
        "            formatted_date = parse_date(pub_date)\n",
        "\n",
        "            headlines.append({\n",
        "                'Source': 'TechCrunch',\n",
        "                'Title': title,\n",
        "                'Link': link,\n",
        "                'Published Date': formatted_date\n",
        "            })\n",
        "\n",
        "        return headlines\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching TechCrunch headlines: {e}\")\n",
        "        return []\n",
        "\n",
        "def fetch_bbc_news_headlines():\n",
        "    \"\"\"Fetch recent headlines from BBC News RSS feed\"\"\"\n",
        "    try:\n",
        "        url = \"http://feeds.bbci.co.uk/news/rss.xml\"\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
        "        }\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        root = ET.fromstring(response.content)\n",
        "        headlines = []\n",
        "\n",
        "        # Parse RSS items\n",
        "        for item in root.findall('.//item')[:4]:\n",
        "            title = item.find('title').text if item.find('title') is not None else \"No title\"\n",
        "            link = item.find('link').text if item.find('link') is not None else \"No link\"\n",
        "            pub_date = item.find('pubDate').text if item.find('pubDate') is not None else \"No date\"\n",
        "\n",
        "            # Parse and format date\n",
        "            formatted_date = parse_date(pub_date)\n",
        "\n",
        "            headlines.append({\n",
        "                'Source': 'BBC News',\n",
        "                'Title': title,\n",
        "                'Link': link,\n",
        "                'Published Date': formatted_date\n",
        "            })\n",
        "\n",
        "        return headlines\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching BBC News headlines: {e}\")\n",
        "        return []\n",
        "\n",
        "def save_to_csv(headlines, filename='news_headlines.csv'):\n",
        "    \"\"\"Save headlines to CSV file with proper encoding and formatting\"\"\"\n",
        "    df = pd.DataFrame(headlines)\n",
        "\n",
        "    # Ensure proper CSV formatting for Excel\n",
        "    df.to_csv(filename, index=False, encoding='utf-8-sig')  # utf-8-sig for Excel compatibility\n",
        "\n",
        "    print(f\"Headlines saved to {filename}\")\n",
        "    print(f\"Total headlines fetched: {len(headlines)}\")\n",
        "    return df\n",
        "\n",
        "def save_to_excel_with_formatting(headlines, filename='news_headlines.xlsx'):\n",
        "    \"\"\"Save to Excel with proper column formatting\"\"\"\n",
        "    try:\n",
        "        df = pd.DataFrame(headlines)\n",
        "\n",
        "        # Create Excel writer\n",
        "        with pd.ExcelWriter(filename, engine='openpyxl') as writer:\n",
        "            df.to_excel(writer, index=False, sheet_name='Headlines')\n",
        "\n",
        "            # Get the workbook and worksheet\n",
        "            workbook = writer.book\n",
        "            worksheet = writer.sheets['Headlines']\n",
        "\n",
        "            # Set column widths for better visibility\n",
        "            worksheet.column_dimensions['A'].width = 15  # Source\n",
        "            worksheet.column_dimensions['B'].width = 60  # Title\n",
        "            worksheet.column_dimensions['C'].width = 40  # Link\n",
        "            worksheet.column_dimensions['D'].width = 20  # Published Date\n",
        "\n",
        "            # Format the date column\n",
        "            for row in range(2, len(df) + 2):  # Start from row 2 (skip header)\n",
        "                worksheet[f'D{row}'].number_format = 'YYYY-MM-DD HH:MM:SS'\n",
        "\n",
        "        print(f\"Headlines saved to Excel file: {filename}\")\n",
        "        print(\"Column widths optimized for better visibility\")\n",
        "        return df\n",
        "    except ImportError:\n",
        "        print(\"Install 'openpyxl' for Excel support: pip install openpyxl\")\n",
        "        return None\n",
        "\n",
        "def print_formatted_summary(headlines):\n",
        "    \"\"\"Print top 2 headlines in formatted summary\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"TOP 2 HEADLINES SUMMARY\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Get top 2 headlines (first 2 from the combined list)\n",
        "    top_headlines = headlines[:2]\n",
        "\n",
        "    for i, headline in enumerate(top_headlines, 1):\n",
        "        print(f\"\\n{i}. {headline['Source']}\")\n",
        "        print(f\"   Title: {headline['Title']}\")\n",
        "        print(f\"   Link: {headline['Link']}\")\n",
        "        print(f\"   Published: {headline['Published Date']}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "def main():\n",
        "    print(\"Starting News Headlines Scraper...\")\n",
        "    print(\"Fetching headlines from TechCrunch and BBC News...\")\n",
        "\n",
        "    # Fetch headlines from both sources\n",
        "    techcrunch_headlines = fetch_techcrunch_headlines()\n",
        "    bbc_headlines = fetch_bbc_news_headlines()\n",
        "\n",
        "    # Combine all headlines\n",
        "    all_headlines = techcrunch_headlines + bbc_headlines\n",
        "\n",
        "    if all_headlines:\n",
        "        # Save to CSV (primary)\n",
        "        df_csv = save_to_csv(all_headlines)\n",
        "\n",
        "        # Save to Excel with proper formatting\n",
        "        df_excel = save_to_excel_with_formatting(all_headlines)\n",
        "\n",
        "        # Print summary\n",
        "        print_formatted_summary(all_headlines)\n",
        "\n",
        "        # Display the dataframe\n",
        "        print(\"\\nðŸ“Š All Headlines:\")\n",
        "        print(df_csv.to_string(index=False, max_colwidth=50))\n",
        "\n",
        "\n",
        "    else:\n",
        "        print(\" No headlines were fetched. Please check your internet connection.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1x-eipRerPF",
        "outputId": "71a6068b-2a17-4f98-eb53-d8365b5618a9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting News Headlines Scraper...\n",
            "Fetching headlines from TechCrunch and BBC News...\n",
            "Headlines saved to news_headlines.csv\n",
            "Total headlines fetched: 8\n",
            "Headlines saved to Excel file: news_headlines.xlsx\n",
            "Column widths optimized for better visibility\n",
            "\n",
            "================================================================================\n",
            "TOP 2 HEADLINES SUMMARY\n",
            "================================================================================\n",
            "\n",
            "1. TechCrunch\n",
            "   Title: Waffles eat Bluesky\n",
            "   Link: https://techcrunch.com/2025/10/05/waffles-eat-bluesky/\n",
            "   Published: 2025-10-05 20:58:42\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "2. TechCrunch\n",
            "   Title: Suspect arrested after threats against TikTokâ€™s Culver City headquarters\n",
            "   Link: https://techcrunch.com/2025/10/05/suspect-arrested-after-threats-against-tiktoks-culver-city-headquarters/\n",
            "   Published: 2025-10-05 18:50:00\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "ðŸ“Š All Headlines:\n",
            "    Source                                              Title                                               Link      Published Date\n",
            "TechCrunch                                Waffles eat Bluesky https://techcrunch.com/2025/10/05/waffles-eat-b... 2025-10-05 20:58:42\n",
            "TechCrunch Suspect arrested after threats against TikTokâ€™s... https://techcrunch.com/2025/10/05/suspect-arres... 2025-10-05 18:50:00\n",
            "TechCrunch Californiaâ€™s new AI safety law shows regulation... https://techcrunch.com/2025/10/05/californias-n... 2025-10-05 17:51:48\n",
            "TechCrunch OpenAI and Jony Ive may be struggling to figure... https://techcrunch.com/2025/10/05/openai-and-jo... 2025-10-05 16:34:26\n",
            "  BBC News Trump urges mediators to 'move fast' as key Gaz... https://www.bbc.com/news/articles/cj3y6g43248o?... 2025-10-05 23:53:33\n",
            "  BBC News Conservatives to pledge Â£5,000 tax rebate for y... https://www.bbc.com/news/articles/c4gzv9j78dyo?... 2025-10-06 01:11:05\n",
            "  BBC News As GisÃ¨le Pelicot faces one of her rapists in c... https://www.bbc.com/news/articles/cdx2d9lynk1o?... 2025-10-05 23:07:07\n",
            "  BBC News The true extent of cyber attacks on UK business... https://www.bbc.com/news/articles/c5ye8zj5l4jo?... 2025-10-06 00:52:33\n"
          ]
        }
      ]
    }
  ]
}